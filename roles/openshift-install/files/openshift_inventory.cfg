# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
{% if install_gluster %}
glusterfs
{% endif %}

# Set variables common for all OSEv3 hosts
[OSEv3:vars]

# SSH user, this user should allow ssh based auth without requiring a password
ansible_ssh_user=ec2-user

# If ansible_ssh_user is not root, ansible_become must be set to true
ansible_become=true

{% if install_gluster %}
# Install CNS
openshift_storage_glusterfs_namespace=glusterfs
openshift_storage_glusterfs_name=storage
openshift_storage_glusterfs_heketi_wipe=true
openshift_storage_glusterfs_wipe=true
openshift_storage_glusterfs_storageclass_default=true
openshift_storage_glusterfs_block_storageclass=true
openshift_storage_glusterfs_block_host_vol_size={{gluster_block_host_volume_size}}
openshift_storage_glusterfs_heketi_wipe=True
openshift_storage_glusterfs_wipe=True

# Automatically deploy the registry using glusterfs
openshift_hosted_manage_registry=true
openshift_hosted_registry_storage_kind=glusterfs
openshift_hosted_registry_storage_volume_size={{registry_volume_size}}Gi
openshift_hosted_registry_selector='region=infra'

# Don't set AWS as default storage provider when using gluster
openshift_storageclass_default=false
{% endif %}

openshift_master_dynamic_provisioning_enabled=true
dynamic_volumes_check=False

# Set cloud provider to AWS
openshift_cloudprovider_kind=aws
openshift_clusterid={{namespace}}
openshift_cloudprovider_aws_access_key={{ lookup('env','AWS_ACCESS_KEY_ID') }}
openshift_cloudprovider_aws_secret_key={{ lookup('env','AWS_SECRET_ACCESS_KEY') }}
openshift_storageclass_parameters={'type': 'gp2', 'encrypted': 'false', 'zone': '{{availability_zone}}'}

deployment_type={{deployment_type}}
# Enable ntp
openshift_clock_enabled=true
# Network plugin
os_sdn_network_plugin_name='{{os_sdn_network_plugin_name}}'

# We need a wildcard DNS setup for our public access to services
openshift_master_default_subdomain={{public_subdomain_prefix}}.{{public_dns_zone}}

# Comment the following to enable htpasswd authentication; defaults to DenyAllPasswordIdentityProvider
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '{{ htpasswd_path }}'}]

{% if install_metrics %}
# Metrics, see: https://docs.openshift.com/enterprise/latest/install_config/cluster_metrics.html
openshift_metrics_install_metrics=true
openshift_metrics_cassandra_storage_type=dynamic
openshift_metrics_cassandra_pvc_size={{metrics_volume_size}}Gi
openshift_metrics_hawkular_nodeselector={'region':'infra'}
openshift_metrics_heapster_nodeselector={'region':'infra'}
openshift_metrics_cassandra_nodeselector={'region':'infra'}
{% if install_gluster %}
openshift_metrics_cassanda_pvc_storage_class_name=glusterfs-storage-block
{% endif %}

{% endif %}

{% if install_logging %}
# Logging, see: https://docs.openshift.com/enterprise/latest/install_config/aggregate_logging.html
openshift_logging_install_logging=true
openshift_logging_es_pvc_dynamic=true
openshift_logging_es_pvc_size={{logging_volume_size}}Gi
openshift_logging_curator_nodeselector={'region':'infra'}
openshift_logging_es_nodeselector={'region':'infra'}
openshift_logging_kibana_nodeselector={'region':'infra'}
openshift_logging_es_memory_limit=4G

{% if install_gluster %}
openshift_logging_es_pvc_storage_class_name=glusterfs-storage-block
{% endif %}

{% endif %}

{% if install_prometheus %}
# Prometheus
openshift_hosted_prometheus_deploy=true
openshift_prometheus_node_selector={'region':'infra'}
# Workaround for BZ https://bugzilla.redhat.com/show_bug.cgi?id=1549936
openshift_prometheus_node_exporter_image_version=v{{ocp_version}}
# Workaround for BZ https://bugzilla.redhat.com/show_bug.cgi?id=1563888
openshift_node_open_ports=[{"service":"Prometheus Node Exporter", "port":"9100/tcp"},{"service":"Prometheus Router Stats", "port":"1936/tcp"}]

# Prometheus storage
openshift_prometheus_storage_access_modes=['ReadWriteOnce']
openshift_prometheus_storage_type=pvc
openshift_prometheus_storage_volume_name=prometheus
openshift_prometheus_storage_volume_size=10Gi

# Prometheus AlertManager storage
openshift_prometheus_alertmanager_storage_access_modes=['ReadWriteOnce']
openshift_prometheus_alertmanager_storage_volume_name=prometheus-alertmanager
openshift_prometheus_alertmanager_storage_volume_size=10Gi
openshift_prometheus_alertmanager_storage_type='pvc'

# Prometheus AlertBuffer storage
openshift_prometheus_alertbuffer_storage_access_modes=['ReadWriteOnce']
openshift_prometheus_alertbuffer_storage_volume_name=prometheus-alertbuffer
openshift_prometheus_alertbuffer_storage_volume_size=10Gi
openshift_prometheus_alertbuffer_storage_type='pvc'

openshift_prometheus_sc_name="gp2"
openshift_prometheus_alertmanager_sc_name="gp2"
openshift_prometheus_alertbuffer_sc_name="gp2"
{% endif %}

{% if master_ssl_key_file is defined and master_ssl_key_file is defined %}
openshift_master_named_certificates=[{"certfile":"/home/{{amazon_user}}/certs/{{public_master_dns}}/{{ master_ssl_cert_file | basename }}","keyfile":"/home/{{amazon_user}}/certs/{{public_master_dns}}/{{master_ssl_key_file | basename }}"}]
openshift_master_overwrite_named_certificates=true
{% endif %}

# Do not run apps on master
{% if install_node_selector %}
osm_default_node_selector="region=primary"
{% endif %}

{% if disable_service_catalog %}
openshift_enable_service_catalog=false
{% endif %}

#disable checks
openshift_disable_check=docker_storage,docker_storage_driver,memory_availability,package_version

# Create the masters host group. 
[masters]
{{master_private_dns_name}} openshift_public_hostname={{public_master_dns}}

# host group for etcd
[etcd]
{{master_private_dns_name}}

# host group for nodes, includes region info
[nodes]
{{master_private_dns_name}} openshift_node_labels="{'region': 'infra', 'zone': 'default'}" openshift_schedulable=true
{% for node in nodes %}
{{node.private_dns_name}} openshift_node_labels="{'region': 'primary', 'zone': '{{ 'west' if loop.index is divisibleby 2 else 'east'}}'}"
{% endfor %}

{% if install_gluster %}
[glusterfs]
{% for node in nodes %}
{% if loop.index < 4 %}
{{node.private_dns_name}} glusterfs_ip={{node.private_ip}}  glusterfs_zone={{loop.index}} glusterfs_devices="[ '/dev/xvdc' ]"
{% endif %}
{% endfor %}
{% endif %}